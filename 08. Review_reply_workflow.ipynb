{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20236daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict, Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07059857",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f294c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "    sentiment: Literal[\"positive\",\"negative\"] = Field(description=\"Sentiment of the review\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c4d5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_mdel = model.with_structured_output(SentimentSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f747902",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "    review: str\n",
    "    sentiment: Literal[\"positive\",\"negative\"]\n",
    "    diagnosis: dict\n",
    "    response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80e417f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState):\n",
    "    prompt = f'For the following review find out the sentiment \\n - {state['review']}'\n",
    "    sentiment = structured_mdel.invoke(prompt).sentiment\n",
    "    return {'sentiment':sentiment}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53369a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type: Literal[\"UX\", \"Performance\", \"Bug\", \"Support\", \"Other\"] = Field(description=\"The category of the issue mentioned in the review\")\n",
    "    tone: Literal[\"angry\", \"frustrated\", \"disappointed\", \"calm\"] = Field(description=\"he emotional tone expressed by the user\")\n",
    "    urgency: Literal[\"low\",\"medium\",\"high\"] = Field(description=\"How urgent or critical the issue appears to be\")\n",
    "\n",
    "diag_model = model.with_structured_output(DiagnosisSchema)\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "    prompt = f\"Diagnose this negative review:\\n\\n{state['review']}\\n return issue_type, tone, urgency\"\n",
    "    response = diag_model.invoke(prompt)\n",
    "    return {'diagnosis': response.model_dump()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b638018",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Diagnose this negative review:\\n\\n{review2}\\n return issue_type, tone, urgency\"\n",
    "response = diag_model.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6dfae769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'issue_type': 'Bug', 'tone': 'frustrated', 'urgency': 'high'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "153ba236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_response(state: ReviewState):\n",
    "    diagnosis = state['diagnosis']\n",
    "    prompt = f\"\"\"You are a support assistant.\n",
    "    The user had a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}', and marked urgency as '{diagnosis['urgency']}'\n",
    "    Write a empathetic, helpful resolution message.\n",
    "    \"\"\"\n",
    "    response = model.invoke(prompt).content\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2e1dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_response(state: ReviewState):\n",
    "    prompt = f\"Write a warm than you message in response to this review:\\n\\n{state['review']}\"\n",
    "    response = model.invoke(prompt).content\n",
    "    return {'response': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92f4b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_based_navigation(state:ReviewState) -> Literal[\"positive_response\",\"run_diagnosis\"]:\n",
    "    if state['sentiment'] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else:\n",
    "        return 'run_diagnosis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf9eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df02b97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a graph\n",
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "# add nodes\n",
    "graph.add_node('find_sentiment', find_sentiment)\n",
    "graph.add_node('run_diagnosis', run_diagnosis)\n",
    "graph.add_node('negative_response', negative_response)\n",
    "graph.add_node('positive_response', positive_response)\n",
    "\n",
    "# add edges\n",
    "graph.add_edge(START,'find_sentiment')\n",
    "graph.add_conditional_edges('find_sentiment', sentiment_based_navigation)\n",
    "graph.add_edge('run_diagnosis','negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "graph.add_edge('positive_response',END)\n",
    "\n",
    "# compile\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fa904e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = \"\"\"I've been using this app for about a month now, and I must say, the user interface is incredibly clean and intutive.\n",
    "Everything is exactly where you'd expect it to be. It's rare to find something that just works without needing a tutorial.\n",
    "Great job to the design team!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcaec720",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = {'review': review1}\n",
    "final_state = workflow.invoke(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5755667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"I've been using this app for about a month now, and I must say, the user interface is incredibly clean and intutive.\\nEverything is exactly where you'd expect it to be. It's rare to find something that just works without needing a tutorial.\\nGreat job to the design team!\",\n",
       " 'sentiment': 'positive',\n",
       " 'response': \"Dear [Reviewer’s Name],\\n\\nThank you so much for your wonderful review! We're thrilled to hear that you've found our app to be clean and intuitive. It’s our goal to create an experience that feels seamless and user-friendly, so your feedback truly means a lot to us.\\n\\nWe'll be sure to pass along your kind words to our design team—they will be delighted to know their hard work has made a positive impact. If you have any more thoughts or suggestions as you continue to use the app, please don’t hesitate to reach out.\\n\\nThanks again for being a part of our community!\\n\\nWarm regards,  \\n[Your Name]  \\n[Your Position]  \\n[Your Company]  \"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd19ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "review2 = \"\"\"I've been trying to login for over an hour now, and the app keeps freezing on the authentication screen. \n",
    "I even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c0abda20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': \"I've been trying to login for over an hour now, and the app keeps freezing on the authentication screen. \\nI even tried reinstalling it, but no luck. This kind of bug is unacceptable, especially when it affects basic functionality.\\n\",\n",
       " 'sentiment': 'negative',\n",
       " 'diagnosis': {'issue_type': 'Bug', 'tone': 'frustrated', 'urgency': 'high'},\n",
       " 'response': \"Subject: We're Here to Help with Your Issue\\n\\nHi [User's Name],\\n\\nI truly understand how frustrating it can be to encounter bugs, especially when you’re trying to accomplish something important. I want to assure you that we’re here to help you resolve this as quickly as possible.\\n\\nCould you please provide me with a few more details about the issue you’re experiencing? Specifically, any error messages you’re seeing or the steps leading up to the problem would be incredibly helpful.\\n\\nThank you for your patience as we work through this together. Your satisfaction is our priority, and I’m committed to getting this resolved for you as soon as possible.\\n\\nLooking forward to hearing from you!\\n\\nBest regards,  \\n[Your Name]  \\n[Your Position]  \\n[Company Name]  \\n[Contact Information]\"}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {'review': review2}\n",
    "final_state = workflow.invoke(initial_state)\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c18c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
